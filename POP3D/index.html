<!DOCTYPE html>
<html>

<style type="text/css">


    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow: 0px 0px 1px 1px rgba(0, 0, 0, 0.35), /* The top layer shadow */ 5px 5px 0 0px #fff, /* The second layer */ 5px 5px 1px 1px rgba(0, 0, 0, 0.35), /* The second layer shadow */ 10px 10px 0 0px #fff, /* The third layer */ 10px 10px 1px 1px rgba(0, 0, 0, 0.35), /* The third layer shadow */ 15px 15px 0 0px #fff, /* The fourth layer */ 15px 15px 1px 1px rgba(0, 0, 0, 0.35), /* The fourth layer shadow */ 20px 20px 0 0px #fff, /* The fifth layer */ 20px 20px 1px 1px rgba(0, 0, 0, 0.35), /* The fifth layer shadow */ 25px 25px 0 0px #fff, /* The fifth layer */ 25px 25px 1px 1px rgba(0, 0, 0, 0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }

    hr {
        border: 0;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.15), rgba(0, 0, 0, 0));
    }


</style>


<head>
    <meta charset="utf-8">
    <meta property="og:title"
          content="{POP}-3D: Open-Vocabulary 3D Occupancy Prediction from Images"/>
    <meta property="og:description" content="POP3D is a novel method for open-vocabulary 3D semantic voxel occupancy map from input 2D images with the objective of enabling 3D grounding,
segmentation and retrieval of free-form language queries"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>POP3D page</title>

    <script>
        function CopyToClipboard(id) {
            var r = document.createRange();
            r.selectNode(document.getElementById(id));
            window.getSelection().removeAllRanges();
            window.getSelection().addRange(r);
            document.execCommand('copy');
            window.getSelection().removeAllRanges();
        }
    </script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1P8DXFXFKM"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-1P8DXFXFKM');
    </script>
    <link rel="stylesheet" href="https://gradio.s3-us-west-2.amazonaws.com/2.6.2/static/bundle.css">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-C2VYDTHPJZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-C2VYDTHPJZ');
</script>

<body>
<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
    </div>
</nav>
<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">{POP}-3D<br>Open-Vocabulary 3D Occupancy Prediction from Images</h1>
                    <div class="is-size-5 publication-authors">
                <div class="column has-text-centered">
                    <h1 class="title is-3 publication-title">NeurIPS 2023</h1>
                    <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://vobecant.github.io" target="_blank"
                   rel="noopener noreferrer">A. Vobecky</a><sup>1,2</sup>,</span>
		<span class="author-block">
                <a href="https://osimeoni.github.io/" target="_blank"
                   rel="noopener noreferrer">O. Siméoni</a><sup>2</sup>,
              </span>
                        <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=XY1PVwYAAAAJ" target="_blank"
                   rel="noopener noreferrer">D. Hurych</a><sup>2</sup>,</span>
                        <span class="author-block">
                <a href="https://scholar.google.fr/citations?user=7atfg7EAAAAJ&hl=en" target="_blank"
                   rel="noopener noreferrer">S. Gydaris</a><sup>2</sup>,
              </span>
                        <span class="author-block">
                <a href="https://abursuc.github.io/" target="_blank" rel="noopener noreferrer">A. Bursuc</a><sup>2</sup>,
              </span>
                        <span class="author-block">
                <a href="https://ptrckprz.github.io/" target="_blank" rel="noopener noreferrer">P. Pérez</a><sup>2</sup>,
              </span>
                        <span class="author-block">
                <a href="https://people.ciirc.cvut.cz/~sivic/" target="_blank"
                   rel="noopener noreferrer">J. Sivic</a><sup>1</sup>
              </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>CIIRC CTU,</span>
                        <span class="author-block"><sup>2</sup>valeo.ai</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">

                            <!-- arXiv Link. -->
                            <span class="link-block">
                  <a href="https://data.ciirc.cvut.cz/public/projects/2022DriveAndSegment/DriveAndSegment__Unsupervised_Semantic_Segmentation_of_Urban_Scenes_via_Cross-modal_Distillation.pdf" target="_blank" rel="noopener noreferrer"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-file-pdf"></i>
                    </span>
                    <span>paper</span>
                  </a>
                </span>

                            <!-- arXiv Link. -->
                            <span class="link-block">
                  <a href="https://arxiv.org/abs/2203.11160" target="_blank" rel="noopener noreferrer"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                            <!-- Code Link. -->
                            <span class="link-block">
                  <a href="https://github.com/vobecant/POP3D" target="_blank" rel="noopener noreferrer"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                            <!-- Video Link. -->
                            <span class="link-block">
                  <a href="" target="_blank" rel="noopener noreferrer"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        We describe an approach to predict open-vocabulary 3D semantic voxel occupancy map 
			    from input 2D images with the objective of enabling 3D grounding,
	segmentation and retrieval of free-form language queries. This is a challenging
	problem because of the 2D-3D ambiguity and the open-vocabulary nature of the
	target tasks, where obtaining annotated training data in 3D is difficult. The con-
	tributions of this work are three-fold. First, we design a new model architecture
	for open-vocabulary 3D semantic occupancy prediction. The architecture consists
	of a 2D-3D encoder together with occupancy prediction and 3D-language heads.
	The output is a dense voxel map of 3D grounded language embeddings enabling a
	range of open-vocabulary tasks. Second, we develop a tri-modal self-supervised
	learning algorithm that leverages three modalities: (i) images, (ii) language and (iii)
	LiDAR point clouds, and enables training the proposed architecture using a strong
	pre-trained vision-language model without the need for any 3D manual language
	annotations. Finally, we demonstrate quantitatively the strengths of the proposed
	model on several open-vocabulary tasks: Zero-shot 3D semantic segmentation
	using existing datasets; 3D grounding and retrieval of free-form language queries,
	using a small dataset that we propose as an extension of nuScenes.
                    </p>
                </div>
                <div>
                    <img class="round" style="width:850px" src="./sources/teaser.png"/>
                </div>
            </div>
        </div>
    </div>
</section>

<hr>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Sample Outputs</h2>
            </div>
        </div>
        <div class="columns is-centered">

            <img class="round" style="width:400px" src="./sources/video128_blend03_v2_10fps_640px_lanczos.gif"/>
        </div>
        <br>
        <div class="columns is-centered">
            <img class="round" style="width:400px" src="./sources/video_stuttgart00_remap_blended03_20fps_crop.gif"/>
            <img class="round" style="width:400px" src="./sources/video_stuttgart01_remap_blended03_20fps_crop2.gif"/>

        </div>

        <div class="content has-text-justified">
            <p>
                <b>Qualitative results.</b>
                <i>Top:</i> An example of pseudo segmentation, i.e., the output of our method where the classes are not
                mapped to the target ground-truth classes.
                <i>Bottom:</i> Two videos from the Cityscapes dataset. To get the pseudo -> ground-truth mapping, we
                apply the Hungarian algorithm.
            </p>
        </div>

    </div>
</section>

<hr>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Explanatory video</h2>
            </div>
        </div>
        <div class="columns is-centered">
            <iframe width="700" height="394" src="https://www.youtube.com/embed/B9LK-Fxu7ao"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
        </div>
    </div>
</section>

<hr>

<section class="section">
    <div class="container is-max-desktop">
        <!-- Demo. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Code</h2>
                <p> We provide inference code of our method on GitHub. Furthermore, to show our method, we provide
                    Gradio demo (try below) and Colab notebook.</p>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/vobecant/DriveAndSegment" target="_blank" rel="noopener noreferrer"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/spaces/vobecant/DaS" target="_blank" rel="noopener noreferrer"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-gamepad"></i>
                    </span>
                    <span>Gradio</span>
                  </a>
                </span>

                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://colab.research.google.com/drive/126tBVYbt1s0STyv8DKhmLoHKpvWcv33H?usp=sharing"
                     target="_blank" rel="noopener noreferrer"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-google"></i>
                    </span>
                    <span>Colab</span>
                  </a>
                </span>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Demo. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h3 class="title is-3">Live Demo</h3>
                <p> If the Huggingface demo below is not loading properly for you, please visit this <a
                        href="https://huggingface.co/spaces/vobecant/DaS" target="_blank" rel="noopener noreferrer">link
                    <i class="fas fa-external-link-alt"></i></a>. </p>
            </div>
        </div>
    </div>
</section>

<section class="section">
    <div id="target"></div>
    <script src="https://gradio.s3-us-west-2.amazonaws.com/2.6.2/static/bundle.js"></script>
    <script>
        launchGradioFromSpaces("vobecant/DaS", "#target")
    </script>
</section>

<hr>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Paper and Supplementary Material</h2>
            </div>
        </div>

        <br>
        <div class="columns is-centered">
            <a href="https://arxiv.org/abs/2203.11160" target="_blank" rel="noopener noreferrer"><img
                    class="layered-paper-big" style="height:175px"
                    src="./sources/paper.png"/></a>
            <span style="font-size:14pt">A. Vobecky, O. Siméoni, D. Hurych, S. Gydaris, A. Bursuc, P. Pérez, and J. Sivic.<br>
				<b>{POP}-3D: Open-Vocabulary 3D Occupancy Prediction from Images</b><br>
                NeurIPS, 2023.<br>
				(hosted on <a href="" target="_blank"
                              rel="noopener noreferrer">ArXiv</a>, <a href="">full PDF</a>)<br>
				</span>
        </div>

        <br>
        <div class="column is-four-fifths">
            <h2 class="title is-3">BibTeX <a href="#" onclick="CopyToClipboard('bibtex');return false;"><span
                    class="icon"><i class="fa fa-copy"></i></span></a></h2>
        </div>
        <div class="columns is-centered">
        <pre><code id="bibtex">@article{vobecky2023POP3D,
  title={{POP}-3D: Open-Vocabulary 3D Occupancy Prediction from Images},
  author={Antonin Vobecky and Oriane Siméoni and David Hurych and Spyros Gidaris and Andrei Bursuc and Patrick Pérez and Josef Sivic},
 booktitle = {Advances in Neural Information Processing Systems},
 volume = {36},
 year = {2023}
}</code></pre>
        </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <!-- Ack. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h4 class="title is-3">Acknowledgements</h4>
                <div class="content has-text-justified">
                    <p>
                        This work was partly supported by the European Regional Development Fund under the project
                        IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000468), and the Ministry of Education, Youth and
                        Sports of the Czech Republic through the e-INFRA CZ (ID:90140). Antonin Vobecky was supported by
                        CTU Student Grant Agency (reg. no. SGS21/184/OHK3/3T/37).
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is forked from source of <a href="https://asgaardlab.github.io/CLIPxGamePhysics/"
                                                                 target="_blank" rel="noopener noreferrer">
                        this page</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>

</html>
