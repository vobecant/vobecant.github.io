<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Antonín Vobecký">
    <meta name="author" content="Antonín Vobecký">

    <title>Antonín Vobecký</title>

    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-C2VYDTHPJZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-C2VYDTHPJZ');
</script>

<body>

<div class="container">
    <div class="row">

        <div class="col-md-4 col-sm-4 col-xs-12 text-center profile-pic-cont">
            <img src="images/antonin.png" title="" class="profile-pic">
        </div>

        <div class="col-md-8 col-sm-8 col-xs-12">
            <br>
            <br>
            <h1 class="title-name">Antonín Vobecký</h1>

            <h3custom>PhD student</h3custom>
            <br>
            <p style="font-size: 120%;text-align: justify;">
            </p>

            <div id="contact">
                <p style="font-size: 120%;text-align: justify;">
                    <b> IMPACT team </b> <br>
                    Czech Technical University in Prague<br>
                    Czech Institute of Informatics, Robotics and Cybernetics<br>
                    Jugoslávských partyzánů 1580/3<br>
                    160 00 Prague 6, Dejvice<br>
                    Czech Republic<br>
                    ✉ antonin (dot) vobecky (at) cvut.cz <!-- <img src="images/mail_cvut.png" title="""> -->
                </p>
            </div>
            <div id="contact_valeo">
                <p style="font-size: 120%;text-align: justify;">
                    <b> valeo.ai team </b> <br>
                    100 Rue de Courcelles, Paris<br>
                    France<br>
                    ✉ antonin (dot) vobecky (at) valeo.com <!-- <img src="images/mail_valeo.png" title="""> -->
                </p>
            </div>

            <div id="contact_ellis">
                <p style="font-size: 120%;text-align: justify;">
                    <b>ELLIS PhD program member</b> <br>
                    ELLIS PhD program <a href="https://ellis.eu/phd-postdoc">webpage</a> <br>
                    personal ELLIS <a
                        href="https://ellis.eu/projects/weakly-supervised-multi-modal-learning-for-scene-understanding">webpage</a>
                </p>
            </div>
            <a href="https://scholar.google.com/citations?user=DGhPzZ0AAAAJ&hl"><img
                    style="margin: 0px; max-height:30px;" src="images/gs.png"></a>
            <a href="https://github.com/vobecant"><img style="margin: 0px; max-height:30px;" src="images/gh.png"></a>
            <a href="https://arxiv.org/search/cs?query=Vobecký%2C+A&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50"><img
                    style="margin: 0px; max-height:30px;" src="images/arxiv.png"></a>

        </div>
    </div>


    <div class="row">
        <div class="col-md-12">
            <h3></h3>
        </div>

        <div class="col-md-12">
            <p style="font-size: 120%;text-align: justify;">
                I am a fourth year PhD student at the <a href="http://impact.ciirc.cvut.cz/">IMPACT</a> (CTU/CIIRC) and
                <a href="https://valeoai.github.io/blog/">valeo.ai</a> teams working under the supervision of <a
                    href="https://people.ciirc.cvut.cz/~sivic/">Josef Sivic</a> (IMPACT), <a
                    href="https://ptrckprz.github.io/">Patrick Pérez</a> and <a
                    href="https://scholar.google.com/citations?hl=en&user=XY1PVwYAAAAJ">David Hurych</a> (both
                valeo.ai). Previously, I got a Master's degree
                and graduated with honors in Computer Science/Computer Vision from CTU in Prague. My research focuses in
                developing algorithms for scene understanding for applications in autonomous driving.
            </p>
        </div>
    </div>

    <div class="row">
        <div class="col-md-12">
            <h3>News</h3>
            <p style="font-size: 110%;text-align: justify;">
                10/2022 - Presenting <a href="https://vobecant.github.io/DriveAndSegment">Drive&Segment</a> at
                ECCV'22 </br>
                07/2022 - <a href="https://vobecant.github.io/DriveAndSegment">Drive&Segment</a> paper accepted as an
                <b>ORAL to ECCV'22</b> conference </br>
                06/2022 - Scientific talks in <a href="https://www.di.ens.fr/willow/">INRIA WILLOW</a> and at <a
                    href="http://imagine.enpc.fr/">IMAGINE</a> team at ENPC Paris. </br>
                03/2022 - <a href="https://vobecant.github.io/DriveAndSegment">Drive&Segment</a> paper available on <a
                    href="http://arxiv.org/abs/2203.11160">arXiv</a> (<a
                    href="https://data.ciirc.cvut.cz/public/projects/2022DriveAndSegment/DriveAndSegment__Unsupervised_Semantic_Segmentation_of_Urban_Scenes_via_Cross-modal_Distillation.pdf"
                    target="_blank" rel="noopener noreferrer">full PDF</a>)</br>
                02/2021 - <a href="https://data.ciirc.cvut.cz/public/projects/2021DummyNet/">DummyNet</a> paper
                presented at AAAI'21.</br>
                10/2019 - <a
                    href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/ADW/Vobecky_Advanced_Pedestrian_Dataset_Augmentation_for_Autonomous_Driving_ICCVW_2019_paper.pdf">Paper</a>
                presented at ICCVw'19.</br>
                06/2019 - Master's degree at CTU in Prague, major Computer Vision.</br>
                09/2017 - Awarded Valeo Scholarship for talented students.</br>
                09/2017 - Awarded Valeo Scholarship for talented students.</br>
                06/2017 - Bachelor's degree at CTU in Prague, major robotics, graduated with honours, Dean's award for
                bachelor thesis.
            </p>
        </div>
    </div>


    <div class="row">
        <div class="col-md-12">
            <h3>Publications</h3>

                        <div class="row">
                <div class="col-3 col-sm-3">
                    <a href="https://vobecant.github.io/DriveAndSegment"><img
                            style="margin: 0px; max-width:100%;"
                            src="POP3D/sources/pop3d_logo.png"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text"><img src="images/new.gif" hspace="5">
                    <b>A. Vobecky</b>, O. Siméoni, D. Hurych, S. Gydaris, A. Bursuc, P. Pérez, and J. Sivic<br>
                    <b>POP-3D: Open-Vocabulary 3D Occupancy Prediction from Images</b> <br>
                    <i>NeurIPS'23</i> <br>
                    <i>Stay tuned for the paper & code!</i>
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col-3 col-sm-3">
                    <a href="https://vobecant.github.io/DriveAndSegment"><img
                            style="margin: 0px; max-width:100%;"
                            src="DriveAndSegment/sources/video128_blend03_v2_10fps_640px_lanczos.gif"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text">
                    <b>A. Vobecky</b>, D. Hurych, O. Siméoni, S. Gydaris, A. Bursuc, P. Pérez, and J. Sivic<br>
                    <b>Drive&Segment: Unsupervised Semantic Segmentation of Urban Scenes via Cross-modal
                        Distillation</b> <br>
                    <i>ECCV'22</i> (<b>oral</b>). <br>
                    [<a href="https://vobecant.github.io/DriveAndSegment" target="_blank" rel="noopener noreferrer">Project
                        page</a>][<a
                            href="https://data.ciirc.cvut.cz/public/projects/2022DriveAndSegment/DriveAndSegment__Unsupervised_Semantic_Segmentation_of_Urban_Scenes_via_Cross-modal_Distillation.pdf"
                            target="_blank" rel="noopener noreferrer">paper</a>][<a
                            href="http://arxiv.org/abs/2203.11160" target="_blank" rel="noopener noreferrer">arXiv</a>][<a
                            href="https://github.com/vobecant/DriveAndSegment" target="_blank"
                            rel="noopener noreferrer">GitHub</a>][<a
                            href='https://huggingface.co/spaces/vobecant/DaS' target="_blank" rel="noopener noreferrer">Gradio
                        application</a>][<a
                            href="https://colab.research.google.com/drive/126tBVYbt1s0STyv8DKhmLoHKpvWcv33H?usp=sharing"
                            target="_blank" rel="noopener noreferrer">Google Colab</a>][<a
                            href="https://www.youtube.com/watch?v=B9LK-Fxu7ao&ab_channel=Anton%C3%ADnVobeck%C3%BD"
                            target="_blank" rel="noopener noreferrer">Explanatory video</a>]
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col-3 col-sm-3">
                    <a href="https://data.ciirc.cvut.cz/public/projects/2021DummyNet/"><img
                            style="margin: 0px; max-width:100%;" src="images/dummynet_illustration_notext.jpg"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text">
                    <b>A. Vobecký</b>, D. Hurych, M. Uřičář, P. Pérez and J. Sivic<br>
                    <b>Artificial Dummies for Urban Dataset Augmentation</b> <br>
                    In <i>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</i>, 2021. <br>
                    [<a href="https://data.ciirc.cvut.cz/public/projects/2021DummyNet/">Project page</a>][<a
                        href="https://arxiv.org/abs/2012.08274">Paper on arXiv</a>][<a
                        href="https://github.com/vobecant/DummyNet">PyTorch code</a>]
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col-3 col-sm-3">
                    <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Uricar_Lets_Get_Dirty_GAN_Based_Data_Augmentation_for_Camera_Lens_WACV_2021_paper.pdf"><img
                            style="margin: 0px; max-width:100%;" src="images/dirtygan.png"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text">
                    M. Uricar, G. Sistu, H. Rashed, <b>A. Vobecký</b>, V. R. Kumar, P. Krizek, F. Burger, S.
                    Yogamani<br>
                    <b>Let's Get Dirty: GAN Based Data Augmentation for Camera Lens Soiling Detection in Autonomous
                        Driving</b> <br>
                    In <i>Proceedings of the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
                    Vision (WACV)</i>, 2021. <br>
                    [<a href="https://openaccess.thecvf.com/content/WACV2021/papers/Uricar_Lets_Get_Dirty_GAN_Based_Data_Augmentation_for_Camera_Lens_WACV_2021_paper.pdf">Paper</a>]
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col-md-3 col-sm-3">
                    <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/ADW/Vobecky_Advanced_Pedestrian_Dataset_Augmentation_for_Autonomous_Driving_ICCVW_2019_paper.pdf"><img
                            style="margin: 0px; max-width:100%;"
                            src="images/iccv2019.png"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text">
                    <b>A. Vobecký</b>, M. Uricar, D. Hurych, R. Skoviera
                    <br>
                    <b>Advanced Pedestrian Dataset Augmentation for Autonomous Driving</b>
                    <br>
                    In <i>Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVw)</i>,
                    2019. <br>
                    [<a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/ADW/Vobecky_Advanced_Pedestrian_Dataset_Augmentation_for_Autonomous_Driving_ICCVW_2019_paper.pdf">Paper</a>]
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col-md-3 col-sm-3">
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373873"><img
                            style="margin: 0px; max-width:100%;"
                            src="images/decision.png"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text">
                    Pavel Jahoda, <b>A. Vobecký</b>, Jan Cech, Jiri Matas
                    <br>
                    <b>Detecting decision ambiguity from facial images</b> <br>
                    In <i>Proceedings of the IEEE International Conference on Automatic Face & Gesture Recognition
                    (FG)</i>, 2019. <br>
                    [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373873">Paper</a>]
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col-md-3 col-sm-3">
                    <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/AUTONUE/Uricar_Desoiling_Dataset_Restoring_Soiled_Areas_on_Automotive_Fisheye_Cameras_ICCVW_2019_paper.pdf"><img
                            style="margin: 0px; max-width:100%;"
                            src="images/desoiling_dataset.png"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text">
                    M. Uricar, J. Ulicny, G. Sistu, H. Rashed, P. Krizek, D. Hurych, <b>A. Vobecký</b>, S. Yogamani
                    <br>
                    <b>Desoiling dataset: Restoring soiled areas on automotive fisheye cameras</b>
                    <br>
                    In <i>Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVw)</i>,
                    2019. <br>
                    [<a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/AUTONUE/Uricar_Desoiling_Dataset_Restoring_Soiled_Areas_on_Automotive_Fisheye_Cameras_ICCVW_2019_paper.pdf">Paper</a>]
                </div>
            </div>
            <br>


            <div class="row">
                <div class="col-md-3 col-sm-3">
                    <a href="https://www.scitepress.org/Papers/2018/66944/66944.pdf"><img
                            style="margin: 0px; max-width:100%;"
                            src="images/intention_estimation.png"></a>
                </div>
                <div class="col-md-9 col-sm-9 pub-text">
                    J. Skovierová, <b>A. Vobecký</b>, M. Uller, R. Skoviera, V. Hlaváč
                    <br>
                    <b>Motion Prediction Influence on the Pedestrian Intention Estimation Near a Zebra Crossing</b> <br>
                    In <i>Proceedings of the International Conference on Vehicle Technology and Intelligent Transport
                    Systems (VEHITS)</i>, 2018.<br>
                    [<a href="https://www.scitepress.org/Papers/2018/66944/66944.pdf">Paper</a>]
                </div>
            </div>
            <br>


        </div>
    </div>

    <div class="row">
        <div class="col-md-12">
            <h3>Misc.</h3>
            RA-L journal reviewer. ECCV'22 reviewer.
        </div>
    </div>


</div> <!-- /container -->


<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
</body>
</html>
